**如果在业务上需要强一致性，就算有主从环境:**
第一.   直接强一致性,  业务读写都在Master上.  
优点, 开发简单.   缺点,  性能呀, slave只能做备机了.

第二.   主从不一致时，可以通过中间件时间窗口解决，比如某个 id 被改了, 我可以在中间层做个标记，应用从中间件访问时碰到id被修改了，那么走主。  ( 当然不单单可用 id 做标记)

**多个冗余表入库场景:**
( 多个冗余表的意思是，为了解决某个多维度分表的问题 )

第一   不加事物，单纯同步阻塞的方式写两个表.       
缺点， 首先是性能的问题，其次是中间宕机， 那么其他的冗余表没法入库。

第二   使用分布式二次提交的方法 ( 2pc , 3pc) 保证入库.   
缺点， 开发的逻辑有些麻烦，需要维护多个事物。

第三   消息写入，消息校验.                
纯异步，性能没的说，靠不靠谱就要看消息队列的ha能力了。

除了那种支付金融业务，其余的场景， 这一二三都可以用的，那么缺数据怎么办？  我们可以写个定时服务脚本来修复多表的一致修复. 
如果涉及到关键数据，推荐使用分布式事物2pc, 3pc， 更高端的消息系统事物的解决方法。  如果想多了解2pc的实现，可以翻找下我以前的博客。

**业务数据缓存问题:**
(还是数据不一样问题，这次跟上面主从类似，缓存数据不够新)

第一  当写请求处理时,  缓存可以同步或异步方法刷新.  也就是说，当数据改变时，才会去被动更新.

第二  缓存强制超时,  不会因为hit命中缓存而延续时间,  脏数据存在时间是有限制的.

第三  写密集时，可以适当用sorted set延迟5s 执行.

数据分表之后的分布式分页查询问题:
(因为热点及增删改过大的问题, 采用了hash分区.  但这样子之后，鬼知道数据跑哪里去了)

第一    如果是hash分的，业务上对于精度又不在乎，比如 limit 100 的需求， 我们可以分别在五个表进行 limit 20，各搜 20个.

第二    对于数据精准度较高标准做法是 跨库表查询，在中间层聚合重排序缓存。 当然这样消耗性能 ！ ！！

第三    除了第一次请求使用limit n，后面的请求都附带上次最大的id， 优化后的语句是  where id > last_id limit n .
对于经常分页查询的数据，还是尽量减少使用hash的方式.   互联网95%的流量都是读流量，过大的读请求可以使用从集群解决。 但对于上述的那种DML性能瓶颈问题， 咱们可以使用 分组+ 分片的方式进行， 我后面会好好的陈述下这种分表结构的优缺点。

***分库分表之前的一些努力 ? 不白扯 ！***
第一, 结合explain和慢查询，优化你的sql和索引；  
第二, 应用级别可以加缓存, redis，memcached，aerospike都可以；
第三, 如果查询的量级过大，就要做主从复制或主主复制，读写分离，可以在应用层或者mysql中间层实现;
第四, 垂直拆分，根据你的业务情况把热点的表拆出分库分表;
第五, 终极绝招，水平切分 ! 选定一个sharding key, 进行分库分表 !
中间其实可以在加一个步骤，就是hhd vs ssd的升级 ！！！提升硬件的效果是相当喜人的，一个200 iops 和 几万的iops … 
另外单表尽量控制到 一千万左右， 单库的表尽量控制在500左右. 
mysql解决性能的路数一般都是按照这个步骤去演化的，成本也是由低到高； 除非你们觉得数据后期会暴增，那么可以一起进行 !!! 

**为什么我们要分库分表?**
有种种的原因，希望大家为了良心，不让后人因为这瓶颈问题而被人嘴上伺候爹妈了.   一般来说原因不外乎就这么几种? 
第一， 分库分实例后绝对好维护.
第二， 数据量大，时常会锁，检索数据慢，维护也是个坑 
第三， 因抗拒数据不一致，流量都在master, 导致单master压力过大.
第四， 就是写大.
第五， 肯定还有…
这几个原因总结就一句话，不好维护，性能太渣. 

**如何选择分库分表的方案**
**第一种 ， 范围分表.** 
这个范围你可以是id范围，也可以是时间等等。 他的优点是开发比较简单, 但缺点也能想到，就是数据的热点过于集中，相对别的区间数据是否均匀也是个问题.  range分表总之各有利弊吧，主要还是看业务。

**第二种， hash取模分表.**
这一种相对公平的分表方式，md5(xxx) % 8 ,  但他的缺点就是扩容是相当的麻烦的，要重新简单迁移数据。

**第三种， range范围 +  hash**
可以想成raid10的磁盘阵列算法，他的优点是为了解决第一种方法中 单区间分表 热点的问题.  我们可以把某个区间进行再次hash到N个表.

**第四种，一致性hash分表**
这个适合的场景很多，但偏向于数据多的场景，想怎么扩展就怎么扩展。 sid = md5(xxx) % 5000 ;  [{'range': (0,512), 'master_db': 'xxx'}, {'range': (513: 1024)} ... ...]
对于那种论坛新闻性质的需求，他有新帖跟老帖之分的, 比如好几年的帖子很少有人关注了，你可以做一些归档处理，所谓的归档就是存起来就行了，不求性能.    像这类明显有新老破旧之分的分表需求，你可以使用range分区，或者range + hash.
对于那种量级大，又要保证读写性能的需求，可以使用hash取摸分表 和 一致性hash分表.   hash mode是一定程度上的随机性. 那么量级大又怎么一回事？ 看下面 !
其实跟dba的朋友聊了很多，对于不可估量的分库分表，一开始就要选择好后期可扩容的架构.   尤其对于那种不可控的业务暴增场景，一开始就要给他上多分库多分表.  

这里额外提一句，在分库分表的场景下，尽量要用mysql的中间件 !  我想当大家到了那种量级，自然也能搞的定。  那么我为什么会推荐大家使用mysql 中间件 ?  如果你是程序控制连接池，那么每次更新db config要反复上线。当然你可以说 用zookeeper做了配置管理，那么当你的应用得到zookeeper更新时，你该如何调整现有的连接池 ?   对于那种跨库join的sql语句，你需要同步模式一个个的遍历结果，然后聚合return ?  等等…    现在互联网公司在分库分表面前，大多会选择 mysql 代理的.   当然代理的性能瓶颈肯定是有的.  现在市面上还没有特别可靠的mysql proxy，只能找个模子二次开发了。  



**如何开始在线迁移操作分库分表 ?**

这是一个很有意思的话，很多开发，尤其是资深点的开发总是想办法搞成那种  类似 “在线不停服务迁移，动态分库分表”  !!! 其实好多朋友，包括我自己经常看一些高质量的技术分享，类似架构公众号那种….  时不时会提到动态分库分表啥的…   其实真正跟DBA接触了后，才知道停服操作才是最简单粗暴，也是架构师和dba们的最爱…    咱们经常玩的一些应用，时不时也会有维护时间….  那么他们在维护什么呢 ?    什么样的场景会迫使他们停服来维护升级呢 ?

我想，如果停服进行迁移分库分表，大家都这么怎么做的?   不外乎就是写一个相当健全的导数程序来进行灌数据 … …

**那么不停服场景下，如何在线分库分表 ？**

**同机器:**

可以采用十分笨拙的 触发器 + 存储过程(hash) +  insert low priority ignore的方式.   原理很简单，我们首先要有个导数的脚本，把数据安卓算法copy过去.  那么问题来了？ 更新的咋办?   我们可以用触发器加存储过程的方法..  触发器只能单纯的监听SQL DML语句，并不能再做复杂的实现，所以可以再套用 存储过程来实现分表的抉择。  

上面的方法听起来很是可靠，但我自己没用过该方案，只是听一些社区分享中提过该方案。  

**跨机器:**

如果库表在其他host上 ?    首先确保导数脚本一直在导数，从以前的大表导到分表里。 导数要一直分片导数，不要一下子导太多的数据，另外可以加 insert low priority ignore参数， 好处在于不影响其他客户端的请求.

然后再开发一个扫描更新binlog日志的脚本，也可以逻辑日志。 这样我们可以确保更新的数据也能应用到分表中.    到此为止就是追赶数据一致性的过程. 

那么还需要停服么?  一个流在持续不断的写源表，另一个在通过读取binlog不停地导数 ，这时间差会造成数据的不一致性 …  这样到底需不需要停服的问题已经很明确了.   我也只能理解到这程度了…   lock tables 锁表命令也是停服的一种 .

**在业务层面采取分库分表的手段?**

常见的几类分库分表的业务场景.     我这里先提下，虽然业务上可以规避下面的场景，但这次重点是在于 分表的策略…    这里特别感觉 sohu dba 徐长华兄和 58架构师沈剑大神 那学到了不少东西. 

**第一种:**

比如我们拿着用户登陆为例，1 %的需求是通过 where username = xxx and password = xxx ，99 %的请求是通过id 查询账户的相关信息…   

这时候如何分表呢 ?  可以按照 id 的方式分表，那么1 %的请求咋办？ 跨表查询呗….  另外加个硬缓存… 当触发用户信息更新时再刷新缓存 。

**第二种:**

文章帖子 , 他的表结构是这样  article_id , uid , topic , created_on , content, title ,updated_on …  我们的查询主要分两类，一个是根据article_id查询文章， 一个是查询uid下的article_id .

他们之间的比率是 80% vs 20% , 对于这类的场景那么我们需要怎么做？  我们可以从文章id下手， 当数据入库的时候我们根据uid信息来创建article_id ,   那么解决了查询用户的所有文章的问题.    那么我怎么定位article_id ？   解决方法是，你创建的文章article_id时，要携带uid信息…   这样你查询article_id时，可以捞出uid所在的库表，然后把article_id相关的其他字段拿出来. 

总结一句话，按照用户id来分表，然后文章id携带用户id的信息. 

**第三种:**

好友表， 业务需求是我想知道我的好友?   别人也想知道他的好友?   表设计师这样的, 如 friend(uid, friend_uid, nick ) 

这样的查询量是 50% 分半的。对于分半查询量的需求，处理起来就容易多了.    可以按照uid和friend_id分别分表，也就是冗余入两份数据，只是索引的范围不一样。  这是典型的空间换时间的处理方法。 

**第四种:**

这次需求是扩展版第二种的需求，不仅仅给是通过文章 id 和 用户uid 查询数据，而且会通过topic类别来查询.   那么现在文章表 article_id , uid , topic , created_on , content, title ,updated_on  产生了三个查询需求。 

肿么办 ?   article_id 和 uid 可以使用第二种方法来实现 ，那么topic话题查询怎么办？  可以使用第三种方法 再建一批topic维度的索引表 !!! 

**靠谱点的mysql高可用方案:**

![img](C:\Users\edong\AppData\Local\YNote\data\qq792E348B85FE0D2278825B41B58AFCC6\c55d5b8977d34ca2a252528544a60e44\20161106154007_54039.png)

我不再阐述myql各种高可用方案的优缺点了， 我就一句话，别用drbd这类共享存储方案，重要的业务不要采用mysql master双写的设计 . 单纯双向复制是靠谱，配置的时候注意步长，不要同时在两个master进行写入数据。

各大公司的mysql高可用都是采用 mysql 主从对换的方法来实现的。 也就是说，同一时间，只有一个主机是支持写入的，当支持写入的master出问题时候，会选出一个跟keepalived关联的slave mysql提升为master.  如果有多个slave mysql，那么不受影响的。 因为对于用户和其他slave来说，对业务和同步slave mysql来说vip就那么一个…   

Mysql mha方案原理如此操作的….  另外如果要保证主备（ master \ standby）的角色数据一致性，那么可以根据业务的重要性选择半同步模式….   

![img](C:\Users\edong\AppData\Local\YNote\data\qq792E348B85FE0D2278825B41B58AFCC6\ace17cd0c9424ab885e86bde4f11c373\20161106170821_77744.jpg.jpeg)

多个数据中心，也就是所谓的异地多活.

第一   一般来说, 只有一个中心可写,  其余可以同步做备机。

第二   同步的方法可以是主从，或者更主流的通过消息异步写入

对于金融支付方面的异地多活，你就别太奢求了.  阿里支付宝天天扯淡最后也抵不过蓝翔技校的挖掘机。。。  支付宝肯定是有多地冗余备份的，但为什么没有有效激活异地多活 ?

END… …